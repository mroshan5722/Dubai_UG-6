{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a048a22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb12b5a",
   "metadata": {
    "papermill": {
     "duration": 0.002773,
     "end_time": "2024-11-20T02:31:51.515809",
     "exception": false,
     "start_time": "2024-11-20T02:31:51.513036",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d83b673",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-20T02:31:51.522074Z",
     "iopub.status.busy": "2024-11-20T02:31:51.521755Z",
     "iopub.status.idle": "2024-11-20T02:32:05.881083Z",
     "shell.execute_reply": "2024-11-20T02:32:05.880032Z"
    },
    "papermill": {
     "duration": 14.364778,
     "end_time": "2024-11-20T02:32:05.883008",
     "exception": false,
     "start_time": "2024-11-20T02:31:51.518230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in the 'label_encoded' column after encoding:\n",
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "folder_name = '../../data/preprocessed_phishing'\n",
    "folder = folder_name + '/mlp/'\n",
    "data_path = folder + 'mlp.csv'\n",
    "# Load the preprocessed dataset\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = df.drop(columns=['label_encoded'])\n",
    "y = df['label_encoded']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Inspect the encoded target column\n",
    "processed_df = pd.read_csv(data_path)\n",
    "print(\"Unique values in the 'label_encoded' column after encoding:\")\n",
    "print(processed_df['label_encoded'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75efe1ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T02:32:05.889305Z",
     "iopub.status.busy": "2024-11-20T02:32:05.888605Z",
     "iopub.status.idle": "2024-11-20T02:33:17.870147Z",
     "shell.execute_reply": "2024-11-20T02:33:17.869075Z"
    },
    "papermill": {
     "duration": 71.986574,
     "end_time": "2024-11-20T02:33:17.872093",
     "exception": false,
     "start_time": "2024-11-20T02:32:05.885519",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1732069927.686279      62 service.cc:145] XLA service 0x7ecbd0005450 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1732069927.686344      62 service.cc:153]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 113/2000\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8487 - loss: 0.4212"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1732069930.739858      62 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9801 - loss: 0.0718 - val_accuracy: 0.9999 - val_loss: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 6.9592e-04 - val_accuracy: 0.9999 - val_loss: 0.0012\n",
      "Epoch 3/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4457e-04 - val_accuracy: 0.9999 - val_loss: 0.0013\n",
      "Epoch 4/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 9.5260e-04 - val_accuracy: 0.9999 - val_loss: 0.0014\n",
      "Epoch 5/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.0525e-05 - val_accuracy: 0.9999 - val_loss: 0.0014\n",
      "Epoch 6/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 1.6552e-04 - val_accuracy: 0.9999 - val_loss: 0.0016\n",
      "Epoch 7/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.2402e-05 - val_accuracy: 0.9999 - val_loss: 0.0016\n",
      "Epoch 8/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.4121e-04 - val_accuracy: 0.9999 - val_loss: 0.0019\n",
      "Epoch 9/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4771e-05 - val_accuracy: 0.9999 - val_loss: 0.0016\n",
      "Epoch 10/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7379e-05 - val_accuracy: 0.9999 - val_loss: 0.0015\n",
      "Epoch 11/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3500e-06 - val_accuracy: 0.9999 - val_loss: 0.0016\n",
      "Epoch 12/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2168e-06 - val_accuracy: 0.9999 - val_loss: 0.0015\n",
      "Epoch 13/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2754e-07 - val_accuracy: 0.9999 - val_loss: 0.0017\n",
      "Epoch 14/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1388e-07 - val_accuracy: 0.9999 - val_loss: 0.0019\n",
      "Epoch 15/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6984e-06 - val_accuracy: 0.9999 - val_loss: 0.0020\n",
      "Epoch 16/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4517e-07 - val_accuracy: 0.9999 - val_loss: 0.0021\n",
      "Epoch 17/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.1232e-05 - val_accuracy: 0.9999 - val_loss: 0.0022\n",
      "Epoch 18/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 9.6928e-05 - val_accuracy: 0.9999 - val_loss: 0.0022\n",
      "Epoch 19/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.0897e-08 - val_accuracy: 0.9999 - val_loss: 0.0023\n",
      "Epoch 20/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.5438e-08 - val_accuracy: 0.9999 - val_loss: 0.0023\n",
      "Test Accuracy: 1.00\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     10000\n",
      "           1       1.00      1.00      1.00     10000\n",
      "\n",
      "    accuracy                           1.00     20000\n",
      "   macro avg       1.00      1.00      1.00     20000\n",
      "weighted avg       1.00      1.00      1.00     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the MLP model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),  # Input layer + first hidden layer\n",
    "    Dropout(0.2),  # Dropout for regularization\n",
    "    Dense(32, activation='relu'),  # Second hidden layer\n",
    "    Dropout(0.2),  # Dropout for regularization\n",
    "    Dense(1, activation='sigmoid')  # Output layer (binary classification)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_split=0.2, \n",
    "                    epochs=20, \n",
    "                    batch_size=32, \n",
    "                    verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
    "\n",
    "# Generate a classification report\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061fde01",
   "metadata": {
    "papermill": {
     "duration": 0.051073,
     "end_time": "2024-11-20T02:33:17.975555",
     "exception": false,
     "start_time": "2024-11-20T02:33:17.924482",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Multi-Layer Perceptron (MLP) Results for Larger Dataset\n",
    "\n",
    "- **Model Architecture:**\n",
    "  - Two hidden layers with 64 and 32 neurons.\n",
    "  - ReLU activation for non-linear transformations.\n",
    "  - Dropout layers for regularization.\n",
    "  - Sigmoid activation in the output layer for binary classification.\n",
    "\n",
    "- **Performance:**\n",
    "  - Achieved **100% accuracy** on training, validation, and test datasets.\n",
    "  - Extremely low loss values.\n",
    "  - Perfect precision, recall, and F1-scores for both classes (`legitimate` and `phishing`).\n",
    "\n",
    "- **Concerns:**\n",
    "  - Potential **overfitting**: The model may be memorizing patterns rather than generalizing.\n",
    "  - Dataset might be simple or features could be highly separable, making classification easy.\n",
    "\n",
    "- **Next Steps for Validation:**\n",
    "  - Use **k-fold cross-validation** to assess generalization across multiple data splits.\n",
    "  - Introduce **feature noise** to test the model's robustness to imperfect data.\n",
    "  - These steps will help confirm whether the results are reliable or highlight potential limitations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb50bec0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T02:33:18.080505Z",
     "iopub.status.busy": "2024-11-20T02:33:18.079899Z",
     "iopub.status.idle": "2024-11-20T02:39:37.502459Z",
     "shell.execute_reply": "2024-11-20T02:39:37.501537Z"
    },
    "papermill": {
     "duration": 379.529581,
     "end_time": "2024-11-20T02:39:37.557078",
     "exception": false,
     "start_time": "2024-11-20T02:33:18.027497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Fold 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Accuracy: 0.9999\n",
      "Training Fold 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Accuracy: 1.0000\n",
      "Training Fold 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Accuracy: 1.0000\n",
      "Training Fold 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 Accuracy: 1.0000\n",
      "Training Fold 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 Accuracy: 1.0000\n",
      "Training Fold 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 6 Accuracy: 1.0000\n",
      "Training Fold 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 7 Accuracy: 1.0000\n",
      "Training Fold 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 8 Accuracy: 0.9999\n",
      "Training Fold 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 9 Accuracy: 1.0000\n",
      "Training Fold 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 10 Accuracy: 1.0000\n",
      "\n",
      "Average Accuracy Across 10 Folds: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Define a function to create the MLP model\n",
    "def create_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_shape=(input_shape,)),\n",
    "        Dropout(0.2),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation='sigmoid')  # Binary classification\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Set up K-Fold Cross-Validation\n",
    "k = 10\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "fold_accuracies = []\n",
    "\n",
    "# Loop through each fold\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X)):\n",
    "    print(f\"Training Fold {fold+1}/{k}\")\n",
    "    \n",
    "    # Split the data into training and testing sets for this fold\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    \n",
    "    # Create a new instance of the model for each fold\n",
    "    model = create_model(X_train.shape[1])\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train,\n",
    "                        validation_split=0.2,\n",
    "                        epochs=10,\n",
    "                        batch_size=32,\n",
    "                        verbose=0)  # Set verbose=1 if you want to see detailed training logs\n",
    "    \n",
    "    # Evaluate the model\n",
    "    loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"Fold {fold+1} Accuracy: {accuracy:.4f}\")\n",
    "    fold_accuracies.append(accuracy)\n",
    "\n",
    "# Calculate the average accuracy across all folds\n",
    "mean_accuracy = np.mean(fold_accuracies)\n",
    "print(f\"\\nAverage Accuracy Across {k} Folds: {mean_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fe635b",
   "metadata": {
    "papermill": {
     "duration": 0.051467,
     "end_time": "2024-11-20T02:39:37.662281",
     "exception": false,
     "start_time": "2024-11-20T02:39:37.610814",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### K-Fold Cross-Validation Results\n",
    "\n",
    "The MLP model performed exceptionally well during 10-fold cross-validation, achieving an average accuracy of **100%**. Each fold's accuracy was consistently either `1.0000` or `0.9999`, showing that the model's performance is robust and reliable across different splits of the data. This suggests that the model has learned meaningful patterns from the dataset and generalizes well to unseen subsets. \n",
    "\n",
    "The slightly lower accuracy in Fold 8 (`0.9999`) could be due to minor differences in the data split or randomness in training, but it does not significantly affect the overall performance. These results indicate that the model is both accurate and consistent. To further validate its robustness, we will now introduce noise into the data and observe how well the model adapts to imperfections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14c8a119",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T02:39:37.768527Z",
     "iopub.status.busy": "2024-11-20T02:39:37.767604Z",
     "iopub.status.idle": "2024-11-20T02:40:49.568764Z",
     "shell.execute_reply": "2024-11-20T02:40:49.567708Z"
    },
    "papermill": {
     "duration": 71.856702,
     "end_time": "2024-11-20T02:40:49.571081",
     "exception": false,
     "start_time": "2024-11-20T02:39:37.714379",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9660 - loss: 0.0936 - val_accuracy: 0.9999 - val_loss: 9.1327e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 9.7052e-04 - val_accuracy: 0.9999 - val_loss: 9.6338e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 7.3495e-04 - val_accuracy: 0.9999 - val_loss: 0.0011\n",
      "Epoch 4/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 3.2172e-04 - val_accuracy: 0.9999 - val_loss: 0.0011\n",
      "Epoch 5/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.4742e-05 - val_accuracy: 0.9999 - val_loss: 0.0013\n",
      "Epoch 6/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8077e-05 - val_accuracy: 0.9999 - val_loss: 0.0014\n",
      "Epoch 7/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2091e-05 - val_accuracy: 0.9999 - val_loss: 0.0016\n",
      "Epoch 8/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3818e-05 - val_accuracy: 0.9999 - val_loss: 0.0016\n",
      "Epoch 9/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8232e-04 - val_accuracy: 0.9999 - val_loss: 0.0014\n",
      "Epoch 10/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.1337e-06 - val_accuracy: 0.9999 - val_loss: 0.0015\n",
      "Epoch 11/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6353e-04 - val_accuracy: 0.9999 - val_loss: 0.0015\n",
      "Epoch 12/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7104e-06 - val_accuracy: 0.9999 - val_loss: 0.0018\n",
      "Epoch 13/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.4677e-06 - val_accuracy: 0.9999 - val_loss: 0.0018\n",
      "Epoch 14/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.2138e-07 - val_accuracy: 0.9999 - val_loss: 0.0016\n",
      "Epoch 15/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8261e-07 - val_accuracy: 0.9999 - val_loss: 0.0017\n",
      "Epoch 16/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9992e-04 - val_accuracy: 0.9999 - val_loss: 0.0018\n",
      "Epoch 17/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.2746e-08 - val_accuracy: 0.9999 - val_loss: 0.0018\n",
      "Epoch 18/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2547e-05 - val_accuracy: 0.9999 - val_loss: 0.0023\n",
      "Epoch 19/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9574e-06 - val_accuracy: 0.9999 - val_loss: 0.0021\n",
      "Epoch 20/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0695e-06 - val_accuracy: 0.9999 - val_loss: 0.0024\n",
      "Test Accuracy with Noise: 0.9999\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     10000\n",
      "           1       1.00      1.00      1.00     10000\n",
      "\n",
      "    accuracy                           1.00     20000\n",
      "   macro avg       1.00      1.00      1.00     20000\n",
      "weighted avg       1.00      1.00      1.00     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Introduce noise into the dataset\n",
    "noise_factor = 0.05  # Adjust the noise level as needed\n",
    "X_noisy = X + np.random.normal(0, noise_factor, X.shape)\n",
    "\n",
    "# Split the noisy dataset into training and testing sets\n",
    "X_train_noisy, X_test_noisy, y_train_noisy, y_test_noisy = train_test_split(\n",
    "    X_noisy, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Recreate the model\n",
    "model_noisy = create_model(X_train_noisy.shape[1])\n",
    "\n",
    "# Train the model on noisy data\n",
    "history_noisy = model_noisy.fit(\n",
    "    X_train_noisy, y_train_noisy,\n",
    "    validation_split=0.2,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate the model on noisy test data\n",
    "loss_noisy, accuracy_noisy = model_noisy.evaluate(X_test_noisy, y_test_noisy, verbose=0)\n",
    "print(f\"Test Accuracy with Noise: {accuracy_noisy:.4f}\")\n",
    "\n",
    "# Generate a classification report for noisy data\n",
    "y_pred_noisy = (model_noisy.predict(X_test_noisy) > 0.5).astype(int)\n",
    "print(classification_report(y_test_noisy, y_pred_noisy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d769fd5",
   "metadata": {
    "papermill": {
     "duration": 0.114288,
     "end_time": "2024-11-20T02:40:49.797526",
     "exception": false,
     "start_time": "2024-11-20T02:40:49.683238",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Analysis of Results After Adding Noise\n",
    "The MLP model performed exceptionally well even after introducing noise into the dataset. With a test accuracy of **99.99%** and perfect precision, recall, and F1-scores, the model demonstrates strong robustness to noisy data. The slight increase in validation loss over epochs indicates the presence of noise, but it did not significantly affect the model’s performance.\n",
    "\n",
    "This result suggests that the model has learned meaningful and generalizable patterns in the data rather than overfitting to specific details. The features appear to be highly distinguishable even under noisy conditions, further validating the model’s reliability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9bf6309",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T02:40:50.023487Z",
     "iopub.status.busy": "2024-11-20T02:40:50.022565Z",
     "iopub.status.idle": "2024-11-20T02:42:05.614402Z",
     "shell.execute_reply": "2024-11-20T02:42:05.613116Z"
    },
    "papermill": {
     "duration": 75.703881,
     "end_time": "2024-11-20T02:42:05.616536",
     "exception": false,
     "start_time": "2024-11-20T02:40:49.912655",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9261 - loss: 0.2743 - val_accuracy: 0.9511 - val_loss: 0.1998\n",
      "Epoch 2/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9497 - loss: 0.2112 - val_accuracy: 0.9513 - val_loss: 0.1974\n",
      "Epoch 3/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9494 - loss: 0.2101 - val_accuracy: 0.9511 - val_loss: 0.1987\n",
      "Epoch 4/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9492 - loss: 0.2076 - val_accuracy: 0.9513 - val_loss: 0.1962\n",
      "Epoch 5/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9503 - loss: 0.2047 - val_accuracy: 0.9514 - val_loss: 0.1958\n",
      "Epoch 6/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9493 - loss: 0.2073 - val_accuracy: 0.9515 - val_loss: 0.1981\n",
      "Epoch 7/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9499 - loss: 0.2048 - val_accuracy: 0.9515 - val_loss: 0.1961\n",
      "Epoch 8/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9494 - loss: 0.2071 - val_accuracy: 0.9514 - val_loss: 0.1948\n",
      "Epoch 9/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9493 - loss: 0.2064 - val_accuracy: 0.9516 - val_loss: 0.1967\n",
      "Epoch 10/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9503 - loss: 0.2026 - val_accuracy: 0.9516 - val_loss: 0.1964\n",
      "Epoch 11/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9496 - loss: 0.2045 - val_accuracy: 0.9516 - val_loss: 0.1963\n",
      "Epoch 12/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9503 - loss: 0.2032 - val_accuracy: 0.9514 - val_loss: 0.1956\n",
      "Epoch 13/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9500 - loss: 0.2025 - val_accuracy: 0.9516 - val_loss: 0.1966\n",
      "Epoch 14/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9502 - loss: 0.2013 - val_accuracy: 0.9514 - val_loss: 0.1958\n",
      "Epoch 15/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9504 - loss: 0.2011 - val_accuracy: 0.9515 - val_loss: 0.1954\n",
      "Epoch 16/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9492 - loss: 0.2042 - val_accuracy: 0.9515 - val_loss: 0.1948\n",
      "Epoch 17/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9494 - loss: 0.2032 - val_accuracy: 0.9516 - val_loss: 0.1955\n",
      "Epoch 18/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9488 - loss: 0.2061 - val_accuracy: 0.9514 - val_loss: 0.1954\n",
      "Epoch 19/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9506 - loss: 0.1992 - val_accuracy: 0.9514 - val_loss: 0.1962\n",
      "Epoch 20/20\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9499 - loss: 0.2031 - val_accuracy: 0.9513 - val_loss: 0.1974\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "Test Accuracy with Noisy Labels and Features: 0.9491\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95      9995\n",
      "           1       0.95      0.95      0.95     10005\n",
      "\n",
      "    accuracy                           0.95     20000\n",
      "   macro avg       0.95      0.95      0.95     20000\n",
      "weighted avg       0.95      0.95      0.95     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add noisy labels (flip 5% of the labels)\n",
    "def add_label_noise(labels, noise_level=0.05):\n",
    "    np.random.seed(42)  # Ensure reproducibility\n",
    "    noisy_labels = labels.copy()\n",
    "    n_noisy = int(noise_level * len(labels))\n",
    "    noisy_indices = np.random.choice(labels.index, n_noisy, replace=False)\n",
    "    noisy_labels.loc[noisy_indices] = 1 - noisy_labels.loc[noisy_indices]  # Flip 0 to 1, and 1 to 0\n",
    "    return noisy_labels\n",
    "\n",
    "# Introduce noisy labels\n",
    "y_noisy = add_label_noise(y, noise_level=0.05)\n",
    "\n",
    "# Split the dataset with noisy labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_noisy, test_size=0.2, random_state=42, stratify=y_noisy)\n",
    "\n",
    "# Increase feature noise (stress testing)\n",
    "def add_feature_noise(features, noise_level=0.1):\n",
    "    np.random.seed(42)  # Ensure reproducibility\n",
    "    noisy_features = features + np.random.normal(0, noise_level, features.shape)\n",
    "    return noisy_features\n",
    "\n",
    "X_train_noisy = add_feature_noise(X_train, noise_level=0.1)\n",
    "X_test_noisy = add_feature_noise(X_test, noise_level=0.1)\n",
    "\n",
    "# Train and evaluate the model with noisy labels and features\n",
    "model = create_model(X_train_noisy.shape[1])\n",
    "history = model.fit(X_train_noisy, y_train,\n",
    "                    validation_split=0.2,\n",
    "                    epochs=20,\n",
    "                    batch_size=32,\n",
    "                    verbose=1)\n",
    "\n",
    "# Evaluate the model on the noisy test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test_noisy, y_test, verbose=0)\n",
    "y_pred = (model.predict(X_test_noisy) > 0.5).astype(int)\n",
    "\n",
    "# Display results\n",
    "print(f\"Test Accuracy with Noisy Labels and Features: {test_accuracy:.4f}\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9bbbf8",
   "metadata": {
    "papermill": {
     "duration": 0.220194,
     "end_time": "2024-11-20T02:42:06.012869",
     "exception": false,
     "start_time": "2024-11-20T02:42:05.792675",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Results with Noisy Labels and Features\n",
    "\n",
    "After introducing noise to both the labels and features, the MLP model achieved a test accuracy of **94.91%**. Precision, recall, and F1-scores for both classes (`legitimate` and `phishing`) were approximately **0.95**, demonstrating that the model remains robust under noisy conditions.\n",
    "\n",
    "#### Observations:\n",
    "1. **Performance Impact**:\n",
    "   - The test accuracy dropped from near-perfect levels (100%) to **94.91%**, reflecting the challenge introduced by noisy data.\n",
    "   - The increased validation loss suggests that noise in both features and labels affected the model’s ability to perfectly classify data.\n",
    "\n",
    "2. **Generalization**:\n",
    "   - Despite the noise, the model retained strong generalization capabilities, with balanced metrics across both classes.\n",
    "\n",
    "3. **Class Balance**:\n",
    "   - Precision, recall, and F1-scores were equally high for both classes, indicating that the noise did not skew the model’s predictions.\n",
    "\n",
    "4. **Robustness**:\n",
    "   - The model demonstrated excellent robustness, maintaining nearly 95% accuracy even under challenging noisy conditions.\n",
    "\n",
    "#### Key Takeaway:\n",
    "The MLP model is highly reliable and robust, even when faced with noisy data. However, the drop in performance highlights the importance of clean data for achieving optimal results."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6123425,
     "sourceId": 9956311,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6123428,
     "sourceId": 9956318,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python (f20dl)",
   "language": "python",
   "name": "f20dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 620.938235,
   "end_time": "2024-11-20T02:42:09.975329",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-20T02:31:49.037094",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
