{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ea22c24",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-21T23:31:43.898938Z",
     "iopub.status.busy": "2024-11-21T23:31:43.898173Z",
     "iopub.status.idle": "2024-11-21T23:31:43.928618Z",
     "shell.execute_reply": "2024-11-21T23:31:43.927157Z",
     "shell.execute_reply.started": "2024-11-21T23:31:43.898898Z"
    },
    "papermill": {
     "duration": 0.005439,
     "end_time": "2024-11-22T02:25:22.945229",
     "exception": false,
     "start_time": "2024-11-22T02:25:22.939790",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Gaussian Naive Bayes: Assumptions\n",
    "\n",
    "Gaussian Naive Bayes is based on **Bayes' Theorem** and assumes:\n",
    "\n",
    "1. **Feature Independence**:\n",
    "   - Features are conditionally independent given the class label.\n",
    "   - This means the presence or value of one feature does not influence another.\n",
    "   - While this is a simplifying assumption, Naive Bayes often performs well even when independence is violated.\n",
    "\n",
    "2. **Gaussian (Normal) Distribution**:\n",
    "   - Continuous features are assumed to follow a Gaussian (normal) distribution.\n",
    "   - The probability density function (PDF) for a feature \\(x\\) is:\n",
    "     $$\n",
    "     P(x|C) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x - \\mu)^2}{2\\sigma^2}}\n",
    "     $$\n",
    "     Where:\n",
    "     - $ \\mu $ : Mean of the feature for the given class.\n",
    "     - $ \\sigma^2 $ : Variance of the feature for the given class.\n",
    "\n",
    "3. **Class Prior Probabilities**:\n",
    "   - The model assumes the prior probability of each class is proportional to its frequency in the training data unless specified otherwise.\n",
    "\n",
    "4. **Feature Contributions**:\n",
    "   - Each feature contributes equally to the outcome based on its likelihood under the Gaussian assumption.\n",
    "\n",
    "---\n",
    "\n",
    "### Practical Considerations\n",
    "- **Violation of Independence**:\n",
    "  - In real-world datasets, features are often correlated, violating the independence assumption. Despite this, Gaussian Naive Bayes is robust and can still perform well.\n",
    "  \n",
    "- **Non-Gaussian Features**:\n",
    "  - Features that do not follow a Gaussian distribution may impact performance. In such cases, feature transformations or alternative Naive Bayes variants (e.g., Multinomial or Bernoulli) should be considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69702ffb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T02:25:22.957011Z",
     "iopub.status.busy": "2024-11-22T02:25:22.956490Z",
     "iopub.status.idle": "2024-11-22T02:25:25.679540Z",
     "shell.execute_reply": "2024-11-22T02:25:25.678452Z"
    },
    "papermill": {
     "duration": 2.731652,
     "end_time": "2024-11-22T02:25:25.681899",
     "exception": false,
     "start_time": "2024-11-22T02:25:22.950247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load preprocessed data\n",
    "X_train = pd.read_csv(\"../../data/preprocessed_phishing/naive_bayes/nb_X_train.csv\")\n",
    "X_test = pd.read_csv(\"../../data/preprocessed_phishing/naive_bayes/nb_X_test.csv\")\n",
    "y_train = pd.read_csv(\"../../data/preprocessed_phishing/naive_bayes/nb_y_train.csv\")\n",
    "y_test = pd.read_csv(\"../../data/preprocessed_phishing/naive_bayes/nb_y_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfc40620",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T02:25:25.692360Z",
     "iopub.status.busy": "2024-11-22T02:25:25.691981Z",
     "iopub.status.idle": "2024-11-22T02:25:25.804831Z",
     "shell.execute_reply": "2024-11-22T02:25:25.803930Z"
    },
    "papermill": {
     "duration": 0.121063,
     "end_time": "2024-11-22T02:25:25.807592",
     "exception": false,
     "start_time": "2024-11-22T02:25:25.686529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Gaussian Naive Bayes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 1/1 [00:00<00:00, 41.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Gaussian Naive Bayes...\n",
      "\n",
      "Accuracy: 0.6761\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Legitimate       0.61      0.99      0.75     10000\n",
      "    Phishing       0.98      0.36      0.53     10000\n",
      "\n",
      "    accuracy                           0.68     20000\n",
      "   macro avg       0.80      0.68      0.64     20000\n",
      "weighted avg       0.80      0.68      0.64     20000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Initialize Gaussian Naive Bayes\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Step 2: Train the model with a progress bar\n",
    "print(\"Training Gaussian Naive Bayes...\")\n",
    "for _ in tqdm(range(1), desc=\"Training Progress\"):\n",
    "    gnb.fit(X_train, y_train.values.ravel())  # Flatten target if needed\n",
    "\n",
    "# Step 3: Evaluate the model\n",
    "print(\"\\nEvaluating Gaussian Naive Bayes...\")\n",
    "y_pred = gnb.predict(X_test)\n",
    "\n",
    "# Step 4: Generate classification report\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred, target_names=[\"Legitimate\", \"Phishing\"])\n",
    "\n",
    "# Display results\n",
    "print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58b7844",
   "metadata": {
    "papermill": {
     "duration": 0.004416,
     "end_time": "2024-11-22T02:25:25.816699",
     "exception": false,
     "start_time": "2024-11-22T02:25:25.812283",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Gaussian Naive Bayes: Results Analysis\n",
    "\n",
    "**Accuracy**:\n",
    "- The overall accuracy of **82.26%** indicates reasonable performance in classifying the data.\n",
    "\n",
    "**Classification Report**:\n",
    "1. **Legitimate (Class 0)**:\n",
    "   - **Precision**: 0.75\n",
    "     - Of all samples predicted as legitimate, 75% were correctly classified.\n",
    "   - **Recall**: 0.97\n",
    "     - The model correctly identified 97% of all legitimate samples.\n",
    "   - **F1-Score**: 0.84\n",
    "     - A good balance between precision and recall, showing strong performance for legitimate samples.\n",
    "\n",
    "2. **Phishing (Class 1)**:\n",
    "   - **Precision**: 0.96\n",
    "     - Of all samples predicted as phishing, 96% were correctly classified.\n",
    "   - **Recall**: 0.68\n",
    "     - The model identified 68% of all phishing samples, indicating some difficulty in capturing all phishing cases.\n",
    "   - **F1-Score**: 0.79\n",
    "     - Reflects a performance trade-off, with higher precision but lower recall.\n",
    "\n",
    "3. **Weighted Averages**:\n",
    "   - Reflect the dataset's class distribution and overall model performance, showing an acceptable but improvable balance between precision and recall.\n",
    "\n",
    "---\n",
    "\n",
    "### Insights\n",
    "1. **Imbalance in Recall**:\n",
    "   - The model performs better in identifying legitimate samples (high recall) but struggles to capture all phishing cases (low recall for phishing).\n",
    "\n",
    "2. **Feature-Model Alignment**:\n",
    "   - Gaussian Naive Bayes assumes feature independence and Gaussian distributions, which might not hold perfectly for this dataset, impacting performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34af6d37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T02:25:25.827771Z",
     "iopub.status.busy": "2024-11-22T02:25:25.826979Z",
     "iopub.status.idle": "2024-11-22T02:25:26.332248Z",
     "shell.execute_reply": "2024-11-22T02:25:26.330962Z"
    },
    "papermill": {
     "duration": 0.513436,
     "end_time": "2024-11-22T02:25:26.334558",
     "exception": false,
     "start_time": "2024-11-22T02:25:25.821122",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Gaussian Naive Bayes with refined parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 1/1 [00:00<00:00, 27.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Gaussian Naive Bayes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.8403\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Legitimate       0.77      0.97      0.86      9922\n",
      "    Phishing       0.96      0.71      0.82     10078\n",
      "\n",
      "    accuracy                           0.84     20000\n",
      "   macro avg       0.86      0.84      0.84     20000\n",
      "weighted avg       0.87      0.84      0.84     20000\n",
      "\n",
      "\n",
      "Performing k-Fold Cross-Validation...\n",
      "\n",
      "Cross-Validation Accuracy Scores: [0.825125 0.810375 0.821375 0.83175  0.819625 0.819    0.821375 0.828375\n",
      " 0.835    0.819625]\n",
      "Mean Accuracy: 0.8231624999999999\n",
      "Standard Deviation: 0.006761344633281163\n"
     ]
    }
   ],
   "source": [
    "# Initialize Gaussian Naive Bayes with refined parameters\n",
    "gnb = GaussianNB(var_smoothing=1e-9)  # Adjust for numerical stability\n",
    "\n",
    "# Adjust sample weights\n",
    "sample_weights = np.where(y_train.values.ravel() == 1, 1.5, 1.0)  # Phishing class gets higher weight\n",
    "\n",
    "print(\"Training Gaussian Naive Bayes with refined parameters...\")\n",
    "for _ in tqdm(range(1), desc=\"Training Progress\"):\n",
    "    gnb.fit(X_train, y_train.values.ravel(), sample_weight=sample_weights)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "print(\"\\nEvaluating Gaussian Naive Bayes...\")\n",
    "y_pred = gnb.predict(X_test)\n",
    "\n",
    "# Calculate accuracy and classification report\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred, target_names=[\"Legitimate\", \"Phishing\"])\n",
    "\n",
    "# Display results\n",
    "print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(report)\n",
    "\n",
    "# Perform k-fold cross-validation to detect overfitting\n",
    "print(\"\\nPerforming k-Fold Cross-Validation...\")\n",
    "cv_scores = cross_val_score(gnb, X_train, y_train.values.ravel(), cv=10, scoring='accuracy')\n",
    "\n",
    "print(\"\\nCross-Validation Accuracy Scores:\", cv_scores)\n",
    "print(\"Mean Accuracy:\", np.mean(cv_scores))\n",
    "print(\"Standard Deviation:\", np.std(cv_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba6bfd4",
   "metadata": {
    "papermill": {
     "duration": 0.004736,
     "end_time": "2024-11-22T02:25:26.344467",
     "exception": false,
     "start_time": "2024-11-22T02:25:26.339731",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Refined Gaussian Naive Bayes: Results Analysis\n",
    "\n",
    "**Accuracy**:\n",
    "- The overall accuracy improved to **84.03%**, indicating better performance after incorporating class weights for the phishing class.\n",
    "\n",
    "**Classification Report**:\n",
    "1. **Legitimate (Class 0)**:\n",
    "   - **Precision**: 0.77  \n",
    "     Of all samples predicted as legitimate, 77% were correct.\n",
    "   - **Recall**: 0.97  \n",
    "     The model identified 97% of legitimate samples correctly.\n",
    "   - **F1-Score**: 0.86  \n",
    "     Reflects strong performance in classifying legitimate cases.\n",
    "\n",
    "2. **Phishing (Class 1)**:\n",
    "   - **Precision**: 0.96  \n",
    "     Of all samples predicted as phishing, 96% were correct.\n",
    "   - **Recall**: 0.71  \n",
    "     An improvement over the previous model, where phishing recall was 68%.\n",
    "   - **F1-Score**: 0.82  \n",
    "     Shows better handling of phishing cases with a balance between precision and recall.\n",
    "\n",
    "3. **Macro Average**:\n",
    "   - Precision, recall, and F1-scores average around **84%**, showing an overall improvement.\n",
    "\n",
    "---\n",
    "\n",
    "### Cross-Validation Results\n",
    "\n",
    "1. **Mean Accuracy**:\n",
    "   - Cross-validation mean accuracy: **82.32%**\n",
    "   - This confirms consistent generalization across different data splits.\n",
    "\n",
    "2. **Standard Deviation**:\n",
    "   - Standard deviation: **0.0068**\n",
    "   - Indicates low variability in accuracy, showing stability and minimal overfitting.\n",
    "\n",
    "---\n",
    "\n",
    "### Insights\n",
    "\n",
    "1. **Improved Recall for Phishing**:\n",
    "   - Weighting the phishing class successfully improved recall, addressing the previous imbalance.\n",
    "\n",
    "2. **Generalization**:\n",
    "   - Cross-validation results confirm the model generalizes well across different data splits.\n",
    "\n",
    "3. **Further Refinement Opportunities**:\n",
    "   - Recall for phishing, while improved, can be further enhanced through feature transformations or advanced engineering techniques.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e559da",
   "metadata": {
    "papermill": {
     "duration": 0.004601,
     "end_time": "2024-11-22T02:25:26.353936",
     "exception": false,
     "start_time": "2024-11-22T02:25:26.349335",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "### Next Steps for Refining Gaussian Naive Bayes\n",
    "\n",
    "1. **Testing Further**:\n",
    "   - Testing the robustness of the model is crucial to ensure its reliability in real-world scenarios. \n",
    "   - By introducing noise into the dataset, we can simulate imperfect or noisy environments and evaluate how well the model maintains its classification performance. \n",
    "   - This step helps identify potential weaknesses in the model and ensures it can handle real-world data variability.\n",
    "\n",
    "2. **Feature Transformation**:\n",
    "   - To better align features with Gaussian Naive Bayes assumptions, we will experiment with feature transformations:\n",
    "     - **Logarithmic Transformation**: Reduces skewness in highly skewed features, making their distribution more Gaussian-like.\n",
    "     - **Polynomial Features**: Captures interactions between features and introduces non-linear components that the model may otherwise miss.\n",
    "     - **Feature Interaction Terms**: Helps uncover relationships between features that may contribute to classification performance.\n",
    "   - These transformations aim to enhance the discriminative power of features while maintaining compatibility with Gaussian Naive Bayes.\n",
    "\n",
    "3. **Final Refinement**:\n",
    "   - After applying feature transformations, the refined dataset will be combined with the adjusted class weighting from previous steps.\n",
    "   - The final model will be evaluated on its ability to balance precision, recall, and overall accuracy across both classes.\n",
    "   - Cross-validation will be repeated to ensure the model generalizes well and is not overfitting due to the transformations or weighting adjustments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff86436d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T02:25:26.366866Z",
     "iopub.status.busy": "2024-11-22T02:25:26.365834Z",
     "iopub.status.idle": "2024-11-22T02:25:26.530792Z",
     "shell.execute_reply": "2024-11-22T02:25:26.529459Z"
    },
    "papermill": {
     "duration": 0.174569,
     "end_time": "2024-11-22T02:25:26.533282",
     "exception": false,
     "start_time": "2024-11-22T02:25:26.358713",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Gaussian Naive Bayes on noisy data...\n",
      "\n",
      "Evaluating Gaussian Naive Bayes on noisy data...\n",
      "\n",
      "Accuracy on Noisy Data: 0.8258\n",
      "\n",
      "Classification Report on Noisy Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Legitimate       0.75      0.97      0.85      9922\n",
      "    Phishing       0.96      0.69      0.80     10078\n",
      "\n",
      "    accuracy                           0.83     20000\n",
      "   macro avg       0.85      0.83      0.82     20000\n",
      "weighted avg       0.85      0.83      0.82     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a noisy version of the training and testing datasets\n",
    "X_train_noisy = X_train.copy()\n",
    "X_test_noisy = X_test.copy()\n",
    "\n",
    "# Add random Gaussian noise to the features\n",
    "noise_train = np.random.normal(0, 0.05, X_train_noisy.shape)  # Mean=0, Std=0.05\n",
    "noise_test = np.random.normal(0, 0.05, X_test_noisy.shape)\n",
    "\n",
    "X_train_noisy += noise_train\n",
    "X_test_noisy += noise_test\n",
    "\n",
    "# Train Gaussian Naive Bayes on the noisy data\n",
    "print(\"\\nTraining Gaussian Naive Bayes on noisy data...\")\n",
    "gnb_noisy = GaussianNB(var_smoothing=1e-9)  # Use the same refined parameters as before\n",
    "gnb_noisy.fit(X_train_noisy, y_train.values.ravel())\n",
    "\n",
    "# Evaluate the model on noisy test data\n",
    "print(\"\\nEvaluating Gaussian Naive Bayes on noisy data...\")\n",
    "y_pred_noisy = gnb_noisy.predict(X_test_noisy)\n",
    "\n",
    "# Calculate accuracy and classification report\n",
    "accuracy_noisy = accuracy_score(y_test, y_pred_noisy)\n",
    "report_noisy = classification_report(y_test, y_pred_noisy, target_names=[\"Legitimate\", \"Phishing\"])\n",
    "\n",
    "# Display results\n",
    "print(f\"\\nAccuracy on Noisy Data: {accuracy_noisy:.4f}\")\n",
    "print(\"\\nClassification Report on Noisy Data:\")\n",
    "print(report_noisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1499c597",
   "metadata": {
    "papermill": {
     "duration": 0.00491,
     "end_time": "2024-11-22T02:25:26.543691",
     "exception": false,
     "start_time": "2024-11-22T02:25:26.538781",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Gaussian Naive Bayes: Results on Noisy Data\n",
    "\n",
    "**Accuracy**:\n",
    "- The model achieved an accuracy of **82.62%** on the noisy dataset, a slight drop compared to its performance on clean data, indicating moderate robustness to noise.\n",
    "\n",
    "**Classification Report**:\n",
    "1. **Legitimate (Class 0)**:\n",
    "   - **Precision**: 0.75  \n",
    "     Of all samples predicted as legitimate, 75% were correctly classified.\n",
    "   - **Recall**: 0.97  \n",
    "     The model identified 97% of legitimate samples correctly.\n",
    "   - **F1-Score**: 0.85  \n",
    "     Demonstrates strong performance in identifying legitimate cases, even with noise.\n",
    "\n",
    "2. **Phishing (Class 1)**:\n",
    "   - **Precision**: 0.96  \n",
    "     Of all samples predicted as phishing, 96% were correctly classified.\n",
    "   - **Recall**: 0.69  \n",
    "     The model captured 69% of phishing cases, showing a slight decline due to the noise.\n",
    "   - **F1-Score**: 0.80  \n",
    "     Indicates that phishing classification is moderately affected by noise.\n",
    "\n",
    "3. **Macro Average**:\n",
    "   - Precision, recall, and F1-scores averaged around **82%-85%**, showing a balanced but slightly degraded performance compared to clean data.\n",
    "\n",
    "---\n",
    "\n",
    "### Insights\n",
    "1. **Robustness to Noise**:\n",
    "   - The model's performance declined slightly with the addition of noise, particularly in the recall for phishing cases.\n",
    "   - This suggests that the features are moderately sensitive to noise, but the model maintains reasonable stability.\n",
    "\n",
    "2. **Next Focus**:\n",
    "   - Enhancing feature distributions through transformations may improve robustness and performance, especially for phishing cases.\n",
    "\n",
    "---\n",
    "\n",
    "### Next Steps\n",
    "Proceed with **feature transformations** to better align features with Gaussian assumptions and potentially improve performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6559139a",
   "metadata": {
    "papermill": {
     "duration": 0.004812,
     "end_time": "2024-11-22T02:25:26.553571",
     "exception": false,
     "start_time": "2024-11-22T02:25:26.548759",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Identifying Skewness in Feature Distributions\n",
    "\n",
    "Before refining the dataset for Gaussian Naive Bayes, it is essential to understand the statistical properties of the features. In this code block, we will:\n",
    "\n",
    "1. **Calculate Feature Statistics**:\n",
    "   - Compute the mean, standard deviation, skewness, minimum, and maximum for each feature in the training dataset.\n",
    "   - These metrics provide a comprehensive overview of the feature distributions.\n",
    "\n",
    "2. **Identify Skewed Features**:\n",
    "   - Features with high skewness (absolute skewness > 1) deviate significantly from a normal distribution.\n",
    "   - Such features may require transformations (e.g., logarithmic scaling) to align better with Gaussian assumptions.\n",
    "\n",
    "3. **Focus on Refinement**:\n",
    "   - This analysis will guide the selective refinement process, ensuring that only highly skewed features are transformed while preserving features that already align well with Gaussian assumptions.\n",
    "\n",
    "By running this code block, you will gain insights into the distributions of all features and identify candidates for refinement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "def9107e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T02:25:26.565382Z",
     "iopub.status.busy": "2024-11-22T02:25:26.565012Z",
     "iopub.status.idle": "2024-11-22T02:25:26.606600Z",
     "shell.execute_reply": "2024-11-22T02:25:26.604767Z"
    },
    "papermill": {
     "duration": 0.050405,
     "end_time": "2024-11-22T02:25:26.608846",
     "exception": false,
     "start_time": "2024-11-22T02:25:26.558441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Summary Statistics:\n",
      "                           Mean  Standard Deviation   Skewness   Minimum  \\\n",
      "url_length            49.456725           84.201335  17.224523  5.000000   \n",
      "starts_with_ip         0.006800            0.082182  12.002961  0.000000   \n",
      "url_entropy            3.941826            0.644900   0.216875  1.007621   \n",
      "has_punycode           0.000487            0.022074  45.258804  0.000000   \n",
      "digit_letter_ratio     0.113286            0.221263   4.402489  0.000000   \n",
      "dot_count              2.248162            1.716658   8.039215  1.000000   \n",
      "at_count               0.011362            0.127215  23.684375  0.000000   \n",
      "dash_count             0.778250            1.590694   7.999229  0.000000   \n",
      "tld_count              0.034688            0.391486  52.986467  0.000000   \n",
      "domain_has_digits      0.093063            0.290522   2.801495  0.000000   \n",
      "subdomain_count        0.883288            1.156269   4.966115  0.000000   \n",
      "nan_char_entropy       0.458588            0.183485   0.493861  0.093588   \n",
      "has_internal_links     0.023062            0.150103   6.354963  0.000000   \n",
      "domain_age_days     4630.494175         3262.656724   0.412905  0.000000   \n",
      "\n",
      "                         Maximum  \n",
      "url_length           5134.000000  \n",
      "starts_with_ip          1.000000  \n",
      "url_entropy             6.010070  \n",
      "has_punycode            1.000000  \n",
      "digit_letter_ratio      4.490683  \n",
      "dot_count              90.000000  \n",
      "at_count                9.000000  \n",
      "dash_count            105.000000  \n",
      "tld_count              51.000000  \n",
      "domain_has_digits       1.000000  \n",
      "subdomain_count        43.000000  \n",
      "nan_char_entropy        1.435677  \n",
      "has_internal_links      1.000000  \n",
      "domain_age_days     14382.000000  \n",
      "\n",
      "Features with High Skewness (|Skewness| > 1):\n",
      "                         Mean  Standard Deviation   Skewness  Minimum  \\\n",
      "url_length          49.456725           84.201335  17.224523      5.0   \n",
      "starts_with_ip       0.006800            0.082182  12.002961      0.0   \n",
      "has_punycode         0.000487            0.022074  45.258804      0.0   \n",
      "digit_letter_ratio   0.113286            0.221263   4.402489      0.0   \n",
      "dot_count            2.248162            1.716658   8.039215      1.0   \n",
      "at_count             0.011362            0.127215  23.684375      0.0   \n",
      "dash_count           0.778250            1.590694   7.999229      0.0   \n",
      "tld_count            0.034688            0.391486  52.986467      0.0   \n",
      "domain_has_digits    0.093063            0.290522   2.801495      0.0   \n",
      "subdomain_count      0.883288            1.156269   4.966115      0.0   \n",
      "has_internal_links   0.023062            0.150103   6.354963      0.0   \n",
      "\n",
      "                        Maximum  \n",
      "url_length          5134.000000  \n",
      "starts_with_ip         1.000000  \n",
      "has_punycode           1.000000  \n",
      "digit_letter_ratio     4.490683  \n",
      "dot_count             90.000000  \n",
      "at_count               9.000000  \n",
      "dash_count           105.000000  \n",
      "tld_count             51.000000  \n",
      "domain_has_digits      1.000000  \n",
      "subdomain_count       43.000000  \n",
      "has_internal_links     1.000000  \n"
     ]
    }
   ],
   "source": [
    "# Calculate skewness and other statistics\n",
    "skewness = X_train.skew()\n",
    "std_dev = X_train.std()\n",
    "mean = X_train.mean()\n",
    "min_val = X_train.min()\n",
    "max_val = X_train.max()\n",
    "\n",
    "# Combine results into a summary DataFrame\n",
    "summary_stats = pd.DataFrame({\n",
    "    \"Mean\": mean,\n",
    "    \"Standard Deviation\": std_dev,\n",
    "    \"Skewness\": skewness,\n",
    "    \"Minimum\": min_val,\n",
    "    \"Maximum\": max_val\n",
    "})\n",
    "\n",
    "# Display the results\n",
    "print(\"Feature Summary Statistics:\")\n",
    "print(summary_stats)\n",
    "\n",
    "# Identify features with high skewness\n",
    "highly_skewed = summary_stats[summary_stats[\"Skewness\"].abs() > 1]\n",
    "print(\"\\nFeatures with High Skewness (|Skewness| > 1):\")\n",
    "print(highly_skewed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9323963",
   "metadata": {
    "papermill": {
     "duration": 0.005118,
     "end_time": "2024-11-22T02:25:26.619289",
     "exception": false,
     "start_time": "2024-11-22T02:25:26.614171",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Analysis of Feature Distributions for Refinement\n",
    "\n",
    "#### Observations on Feature Distributions\n",
    "\n",
    "1. **Highly Skewed Features**:\n",
    "   - Several features exhibit high skewness (absolute skewness > 1), indicating significant deviation from a normal distribution:\n",
    "     - `url_length` (Skewness: 17.22)\n",
    "     - `starts_with_ip` (Skewness: 12.00)\n",
    "     - `has_punycode` (Skewness: 45.25)\n",
    "     - `digit_letter_ratio` (Skewness: 4.40)\n",
    "     - `dot_count` (Skewness: 8.04)\n",
    "     - `at_count` (Skewness: 23.68)\n",
    "     - `dash_count` (Skewness: 8.00)\n",
    "     - `tld_count` (Skewness: 52.98)\n",
    "     - `domain_has_digits` (Skewness: 2.80)\n",
    "     - `subdomain_count` (Skewness: 4.97)\n",
    "     - `has_internal_links` (Skewness: 6.35)\n",
    "\n",
    "2. **Moderate and Low Skewness**:\n",
    "   - Features like `url_entropy` (Skewness: 0.21) and `domain_age_days` (Skewness: 0.41) are closer to a normal distribution and may not need transformations.\n",
    "\n",
    "3. **Binary Features**:\n",
    "   - Features like `starts_with_ip` and `has_punycode` are binary (`0` or `1`) and do not require transformations, as their distribution is inherently discrete.\n",
    "\n",
    "---\n",
    "\n",
    "#### Why Refinement is Necessary\n",
    "\n",
    "1. **Gaussian Assumptions**:\n",
    "   - Gaussian Naive Bayes assumes that each feature follows a **normal distribution**.\n",
    "   - Features with high skewness deviate significantly from this assumption, which may lead to inaccurate probability estimations.\n",
    "\n",
    "2. **Improving Robustness**:\n",
    "   - Transforming skewed features (e.g., via logarithmic scaling) can make their distribution more Gaussian-like, improving the model's overall performance and robustness.\n",
    "\n",
    "3. **Focus on Critical Features**:\n",
    "   - Refining only highly skewed features helps maintain the integrity of well-distributed features, preventing unnecessary transformations that could degrade performance.\n",
    "\n",
    "---\n",
    "\n",
    "#### Recommendations for Refinement\n",
    "\n",
    "1. **Logarithmic Transformations**:\n",
    "   - Apply to features with extreme skewness and large ranges, such as `url_length`, `dot_count`, and `dash_count`.\n",
    "\n",
    "2. **Retain Binary Features**:\n",
    "   - Leave features like `starts_with_ip` and `has_punycode` unchanged, as they are already binary and not continuous.\n",
    "\n",
    "3. **Selective Application**:\n",
    "   - Focus transformations on features with absolute skewness > 2, ensuring that the refinement aligns with Gaussian assumptions without overcomplicating the feature space.\n",
    "\n",
    "By addressing these points, we aim to align the feature distributions better with Gaussian Naive Bayes' assumptions, improving the model's ability to classify phishing and legitimate cases accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c78d97a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T02:25:26.631256Z",
     "iopub.status.busy": "2024-11-22T02:25:26.630903Z",
     "iopub.status.idle": "2024-11-22T02:25:26.654733Z",
     "shell.execute_reply": "2024-11-22T02:25:26.653588Z"
    },
    "papermill": {
     "duration": 0.032517,
     "end_time": "2024-11-22T02:25:26.656976",
     "exception": false,
     "start_time": "2024-11-22T02:25:26.624459",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformations applied to highly skewed features:\n",
      "['url_length', 'digit_letter_ratio', 'dot_count', 'dash_count', 'subdomain_count', 'domain_has_digits']\n"
     ]
    }
   ],
   "source": [
    "# Create a copy of the training and testing datasets for transformation\n",
    "X_train_transformed = X_train.copy()\n",
    "X_test_transformed = X_test.copy()\n",
    "\n",
    "# Features with high skewness identified earlier\n",
    "skewed_features = [\n",
    "    \"url_length\", \"digit_letter_ratio\", \"dot_count\", \n",
    "    \"dash_count\", \"subdomain_count\", \"domain_has_digits\"\n",
    "]\n",
    "\n",
    "# Apply log transformation to reduce skewness\n",
    "for feature in skewed_features:\n",
    "    X_train_transformed[feature] = np.log1p(X_train_transformed[feature])  # log1p avoids log(0)\n",
    "    X_test_transformed[feature] = np.log1p(X_test_transformed[feature])\n",
    "\n",
    "# Check the transformed data\n",
    "print(\"Transformations applied to highly skewed features:\")\n",
    "print(skewed_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8636cebd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T02:25:26.669500Z",
     "iopub.status.busy": "2024-11-22T02:25:26.669156Z",
     "iopub.status.idle": "2024-11-22T02:25:26.768744Z",
     "shell.execute_reply": "2024-11-22T02:25:26.767564Z"
    },
    "papermill": {
     "duration": 0.108499,
     "end_time": "2024-11-22T02:25:26.770860",
     "exception": false,
     "start_time": "2024-11-22T02:25:26.662361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Gaussian Naive Bayes on transformed data...\n",
      "\n",
      "Evaluating Gaussian Naive Bayes on transformed data...\n",
      "\n",
      "Accuracy on Transformed Data: 0.9235\n",
      "\n",
      "Classification Report on Transformed Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Legitimate       0.89      0.96      0.93      9922\n",
      "    Phishing       0.96      0.88      0.92     10078\n",
      "\n",
      "    accuracy                           0.92     20000\n",
      "   macro avg       0.93      0.92      0.92     20000\n",
      "weighted avg       0.93      0.92      0.92     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Gaussian Naive Bayes on transformed data\n",
    "print(\"\\nTraining Gaussian Naive Bayes on transformed data...\")\n",
    "gnb_transformed = GaussianNB(var_smoothing=1e-9)  # Retain refined hyperparameter\n",
    "gnb_transformed.fit(X_train_transformed, y_train.values.ravel())\n",
    "\n",
    "# Evaluate the model on the transformed test data\n",
    "print(\"\\nEvaluating Gaussian Naive Bayes on transformed data...\")\n",
    "y_pred_transformed = gnb_transformed.predict(X_test_transformed)\n",
    "\n",
    "# Calculate accuracy and classification report\n",
    "accuracy_transformed = accuracy_score(y_test, y_pred_transformed)\n",
    "report_transformed = classification_report(y_test, y_pred_transformed, target_names=[\"Legitimate\", \"Phishing\"])\n",
    "\n",
    "# Display results\n",
    "print(f\"\\nAccuracy on Transformed Data: {accuracy_transformed:.4f}\")\n",
    "print(\"\\nClassification Report on Transformed Data:\")\n",
    "print(report_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713c7080",
   "metadata": {
    "papermill": {
     "duration": 0.005046,
     "end_time": "2024-11-22T02:25:26.781371",
     "exception": false,
     "start_time": "2024-11-22T02:25:26.776325",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Gaussian Naive Bayes: Results on Transformed Data\n",
    "\n",
    "**Accuracy**:\n",
    "- The model achieved an impressive accuracy of **92.35%** on the transformed dataset, marking a significant improvement over previous evaluations.\n",
    "\n",
    "**Classification Report**:\n",
    "1. **Legitimate (Class 0)**:\n",
    "   - **Precision**: 0.89  \n",
    "     Of all samples predicted as legitimate, 89% were correct.\n",
    "   - **Recall**: 0.96  \n",
    "     The model identified 96% of legitimate samples correctly.\n",
    "   - **F1-Score**: 0.93  \n",
    "     Demonstrates strong performance in classifying legitimate cases.\n",
    "\n",
    "2. **Phishing (Class 1)**:\n",
    "   - **Precision**: 0.96  \n",
    "     Of all samples predicted as phishing, 96% were correct.\n",
    "   - **Recall**: 0.88  \n",
    "     The model captured 88% of phishing cases, a noticeable improvement.\n",
    "   - **F1-Score**: 0.92  \n",
    "     Reflects a well-balanced performance for phishing classification.\n",
    "\n",
    "3. **Macro and Weighted Averages**:\n",
    "   - Both averages are approximately **92%**, showcasing a consistent and balanced model across classes.\n",
    "\n",
    "---\n",
    "\n",
    "### Insights\n",
    "\n",
    "1. **Impact of Transformations**:\n",
    "   - The log transformations applied to highly skewed features significantly improved the model's performance.\n",
    "   - By better aligning feature distributions with Gaussian assumptions, the model achieved higher recall for phishing cases without compromising legitimate case detection.\n",
    "\n",
    "2. **Balanced Performance**:\n",
    "   - The precision-recall balance indicates that the model is effective in identifying both legitimate and phishing cases.\n",
    "\n",
    "3. **Comparison**:\n",
    "   - The transformed dataset outperformed both the original and noisy datasets, suggesting that feature refinement was critical for enhancing the model.\n",
    "\n",
    "---\n",
    "\n",
    "### Next Steps\n",
    "1. **Final Validation**:\n",
    "   - Perform cross-validation on the transformed dataset to ensure generalization.\n",
    "\n",
    "2. **Stress Testing with Noise**:\n",
    "   - Evaluate the model’s performance by introducing noise into the transformed dataset to test its robustness further.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac5cfb8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T02:25:26.793240Z",
     "iopub.status.busy": "2024-11-22T02:25:26.792879Z",
     "iopub.status.idle": "2024-11-22T02:25:27.301647Z",
     "shell.execute_reply": "2024-11-22T02:25:27.300434Z"
    },
    "papermill": {
     "duration": 0.517303,
     "end_time": "2024-11-22T02:25:27.303746",
     "exception": false,
     "start_time": "2024-11-22T02:25:26.786443",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing 10-Fold Cross-Validation on Transformed Data...\n",
      "\n",
      "Cross-Validation Accuracy Scores: [0.92725  0.919375 0.91825  0.927875 0.921875 0.92125  0.924875 0.926125\n",
      " 0.93075  0.922625]\n",
      "Mean Accuracy: 0.924025\n",
      "Standard Deviation: 0.003805752225250599\n"
     ]
    }
   ],
   "source": [
    "# Perform cross-validation on the transformed training data\n",
    "print(\"\\nPerforming 10-Fold Cross-Validation on Transformed Data...\")\n",
    "cv_scores_transformed = cross_val_score(\n",
    "    gnb_transformed, \n",
    "    X_train_transformed, \n",
    "    y_train.values.ravel(), \n",
    "    cv=10, \n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "# Display cross-validation results\n",
    "print(\"\\nCross-Validation Accuracy Scores:\", cv_scores_transformed)\n",
    "print(\"Mean Accuracy:\", np.mean(cv_scores_transformed))\n",
    "print(\"Standard Deviation:\", np.std(cv_scores_transformed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21c01e7",
   "metadata": {
    "papermill": {
     "duration": 0.005058,
     "end_time": "2024-11-22T02:25:27.314296",
     "exception": false,
     "start_time": "2024-11-22T02:25:27.309238",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Gaussian Naive Bayes: Cross-Validation Results on Transformed Data\n",
    "\n",
    "**Cross-Validation Accuracy Scores**:\n",
    "- Individual Fold Scores:  \n",
    "  `[0.92725, 0.919375, 0.91825, 0.927875, 0.921875, 0.92125, 0.924875, 0.926125, 0.93075, 0.922625]`\n",
    "\n",
    "**Mean Accuracy**:\n",
    "- The model achieved a mean accuracy of **92.40%** across 10 folds, indicating consistent performance.\n",
    "\n",
    "**Standard Deviation**:\n",
    "- The standard deviation of **0.0038** reflects minimal variance between folds, showcasing excellent generalization and stability.\n",
    "\n",
    "---\n",
    "\n",
    "### Insights\n",
    "\n",
    "1. **Consistency Across Folds**:\n",
    "   - The small standard deviation highlights that the model performs reliably on different splits of the dataset.\n",
    "\n",
    "2. **Generalization Ability**:\n",
    "   - The high mean accuracy confirms the model’s strong generalization to unseen data, a critical indicator of its robustness.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6682bee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T02:25:27.326644Z",
     "iopub.status.busy": "2024-11-22T02:25:27.326231Z",
     "iopub.status.idle": "2024-11-22T02:25:27.480016Z",
     "shell.execute_reply": "2024-11-22T02:25:27.478914Z"
    },
    "papermill": {
     "duration": 0.163025,
     "end_time": "2024-11-22T02:25:27.482615",
     "exception": false,
     "start_time": "2024-11-22T02:25:27.319590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Gaussian Naive Bayes on noisy transformed data...\n",
      "\n",
      "Evaluating Gaussian Naive Bayes on noisy transformed data...\n",
      "\n",
      "Accuracy on Noisy Transformed Data: 0.9192\n",
      "\n",
      "Classification Report on Noisy Transformed Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Legitimate       0.89      0.96      0.92      9922\n",
      "    Phishing       0.95      0.88      0.92     10078\n",
      "\n",
      "    accuracy                           0.92     20000\n",
      "   macro avg       0.92      0.92      0.92     20000\n",
      "weighted avg       0.92      0.92      0.92     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add Gaussian noise to the transformed features\n",
    "X_train_transformed_noisy = X_train_transformed + np.random.normal(0, 0.05, X_train_transformed.shape)\n",
    "X_test_transformed_noisy = X_test_transformed + np.random.normal(0, 0.05, X_test_transformed.shape)\n",
    "\n",
    "# Train Gaussian Naive Bayes on noisy transformed data\n",
    "print(\"\\nTraining Gaussian Naive Bayes on noisy transformed data...\")\n",
    "gnb_transformed_noisy = GaussianNB(var_smoothing=1e-9)\n",
    "gnb_transformed_noisy.fit(X_train_transformed_noisy, y_train.values.ravel())\n",
    "\n",
    "# Evaluate the model on noisy transformed test data\n",
    "print(\"\\nEvaluating Gaussian Naive Bayes on noisy transformed data...\")\n",
    "y_pred_transformed_noisy = gnb_transformed_noisy.predict(X_test_transformed_noisy)\n",
    "\n",
    "# Calculate accuracy and classification report\n",
    "accuracy_transformed_noisy = accuracy_score(y_test, y_pred_transformed_noisy)\n",
    "report_transformed_noisy = classification_report(y_test, y_pred_transformed_noisy, target_names=[\"Legitimate\", \"Phishing\"])\n",
    "\n",
    "# Display results\n",
    "print(f\"\\nAccuracy on Noisy Transformed Data: {accuracy_transformed_noisy:.4f}\")\n",
    "print(\"\\nClassification Report on Noisy Transformed Data:\")\n",
    "print(report_transformed_noisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76302a1",
   "metadata": {
    "papermill": {
     "duration": 0.005422,
     "end_time": "2024-11-22T02:25:27.493869",
     "exception": false,
     "start_time": "2024-11-22T02:25:27.488447",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Gaussian Naive Bayes: Stress Test Results on Noisy Transformed Data\n",
    "\n",
    "**Accuracy**:\n",
    "- The model achieved an accuracy of **91.76%** on the noisy transformed dataset, maintaining high performance even under stress.\n",
    "\n",
    "**Classification Report**:\n",
    "1. **Legitimate (Class 0)**:\n",
    "   - **Precision**: 0.89  \n",
    "     Of all samples predicted as legitimate, 89% were correct.\n",
    "   - **Recall**: 0.96  \n",
    "     The model identified 96% of legitimate cases correctly.\n",
    "   - **F1-Score**: 0.92  \n",
    "     Reflects consistent performance despite added noise.\n",
    "\n",
    "2. **Phishing (Class 1)**:\n",
    "   - **Precision**: 0.95  \n",
    "     Of all samples predicted as phishing, 95% were correct.\n",
    "   - **Recall**: 0.88  \n",
    "     The model captured 88% of phishing cases, showcasing robustness.\n",
    "   - **F1-Score**: 0.91  \n",
    "     Highlights balanced performance for phishing classification.\n",
    "\n",
    "3. **Macro and Weighted Averages**:\n",
    "   - Both averages remain steady at **92%**, demonstrating the model’s resilience to noisy data.\n",
    "\n",
    "---\n",
    "\n",
    "### Final Insights\n",
    "\n",
    "1. **Robustness to Noise**:\n",
    "   - The model handled noisy conditions effectively, with minimal performance degradation.\n",
    "\n",
    "2. **Generalization**:\n",
    "   - Cross-validation and stress testing confirm the model generalizes well to unseen and imperfect data.\n",
    "\n",
    "3. **Feature Refinement Success**:\n",
    "   - The transformations applied to highly skewed features improved the alignment with Gaussian assumptions, significantly enhancing performance.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6138929,
     "sourceId": 9977211,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python (f20dl)",
   "language": "python",
   "name": "f20dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7.905413,
   "end_time": "2024-11-22T02:25:28.121120",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-22T02:25:20.215707",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
