{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c6fd4d1-16fc-4229-880a-9074dc75462f",
   "metadata": {},
   "source": [
    "# Phishing Dataset - Download, Preprocessing, and Model Pipeline\n",
    "\n",
    "In this notebook, we will be setting up the **Phishing URL Detection** dataset for machine learning models. This notebook is designed to help you understand the entire workflow, from dataset acquisition, preparing the data for model training, creating models and training the models with the dataset.\n",
    "\n",
    "Let’s dive in!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72385551-8688-44ba-b4e3-1f89056e7b3f",
   "metadata": {},
   "source": [
    "## Downloading the Phishing Dataset\n",
    "\n",
    "We will start by downloading the **Phishing URL Detection** dataset using the `Kaggle API`. The dataset will be downloaded into the `raw_data` directory.\n",
    "\n",
    "Note: Make sure you already have the Kaggle API set up, as outlined in the project's README file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec2462fc-ffe7-4a7b-afcd-a9ca5aa7b82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "BASE_DIR = os.path.abspath('..')\n",
    "RAW_DATA_DIR = os.path.join(BASE_DIR, 'data/raw_data/phishing')\n",
    "sys.path.append(os.path.join(BASE_DIR, 'scripts'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a17e64bf-bd35-43ad-877a-547b91dda846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading sergioagudelo/phishing-url-detection dataset...\n",
      "Dataset URL: https://www.kaggle.com/datasets/sergioagudelo/phishing-url-detection\n",
      "Downloaded and extracted to /home/rishupishu/Documents/HWUD/YEAR 4/SEM 1/F20DL/CW/Dubai_UG-6/data/raw_data/phishing\n"
     ]
    }
   ],
   "source": [
    "from download_data import download_dataset\n",
    "phishing_dataset = 'sergioagudelo/phishing-url-detection'\n",
    "download_dataset(phishing_dataset, RAW_DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7a7316-43b9-4ed1-bc95-8fd303eb1ec8",
   "metadata": {},
   "source": [
    "## Inspect the Dataset\n",
    "\n",
    "Now that we have downloaded the dataset, let’s load it into a Pandas DataFrame and inspect the first few rows to understand the data structure. This may take a few seconds...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cec07a28-3b93-4668-8c2d-88ebef84a8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = os.path.join(RAW_DATA_DIR, 'out.csv')\n",
    "df = pd.read_csv(dataset)\n",
    "\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fe2243-4c1c-40ab-a60f-417e10f4d63d",
   "metadata": {},
   "source": [
    "## Preprocessing the Data\n",
    "\n",
    "Next, we will preprocess the dataset to prepare it for machine learning models. The steps will include:\n",
    "\n",
    "1. Load the data.\n",
    "2. Handling missing values.\n",
    "3. Encoding categorical features\n",
    "4. Outlier Detection and Removal\n",
    "5. Normalization/Standarization\n",
    "6. Flattening the Data\n",
    "7. Principle Component Analysis\n",
    "8. Splitting the data into training and testing sets.\n",
    "9. Saving the data into flattened and unflattened sets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdd5ec7-e8f8-4e88-a8f2-36b38d4d60c4",
   "metadata": {},
   "source": [
    "### Load the data\n",
    "\n",
    "In this step, we will load the phishing dataset from the specified file path using pandas. The dataset contains information on URLs and various features that will be used for phishing detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "32769eda-b7ff-4f57-a39a-4f89a3abad79",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocessing_pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# You can now directly call the preprocessing pipeline function\u001b[39;00m\n\u001b[1;32m      2\u001b[0m RAW_DATA_PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data/raw_data/phishing/out.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mpreprocessing_pipeline\u001b[49m(RAW_DATA_PATH, use_pca\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preprocessing_pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "from preprocess_phishing_data import preprocessing_pipeline\n",
    "RAW_DATA_PATH = './data/raw_data/phishing/out.csv'\n",
    "preprocessing_pipeline(RAW_DATA_PATH, use_pca=True, n_components=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e0cf11-05fd-4f2f-a2f6-352dd0cf81bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
